{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2v_vs_fasttext.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FzgSc18cyHCT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Comparaison between Word2vec and FastText\n",
        "\n",
        "A text can be interpreted from different perspectives among them let’s consider the words, the sentences, and the full document. In modern NLP – not gimmicks such keyword search – different methodologies consider those 3 dimensions when they try, for instance, to run a topic detection.\n",
        "\n",
        "Word2vec treats each word in corpus like an atomic entity and generates a vector for each word. In this sense Word2vec is very similar to Glove – both treat words as the smallest unit to train on.\n",
        "\n",
        "FastText – which is essentially an extension of word2vec model – treats each word as composed of character n-grams. So the vector for a word is made of the sum of this character n-grams. For example, the word vector “apple” is a sum of the vectors of the n-grams:\n",
        "\n",
        "**“<ap”, “app”, ”appl”, ”apple”, ”apple>”, “ppl”, “pple”, ”pple>”, “ple”, ”ple>”, ”le>”**\n",
        "\n",
        "(assuming hyperparameters for smallest ngram[minn] is 3 and largest ngram[maxn] is 6)."
      ]
    },
    {
      "metadata": {
        "id": "HbDKZqAZwNg_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --quiet lxml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ZOsUgLFv7Ac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import re\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import lxml.etree\n",
        "import logging\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N4I75bOFv7Ac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
        "                    level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cq68tunUv7Ac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#download the data\n",
        "urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")\n",
        "# extract subtitle\n",
        "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
        "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
        "input_text = '\\n'.join(doc.xpath('//content/text()'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjmLPOGIv7At",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove parenthesis \n",
        "input_text_noparens = re.sub(r'\\([^)]*\\)', '', input_text)\n",
        "# store as list of sentences\n",
        "sentences_strings_ted = []\n",
        "for line in input_text_noparens.split('\\n'):\n",
        "    m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
        "    sentences_strings_ted.extend(sent for sent in m.groupdict()['postcolon'].split('.') if sent)\n",
        "# store as list of lists of words\n",
        "sentences_ted = []\n",
        "for sent_str in sentences_strings_ted:\n",
        "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
        "    sentences_ted.append(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jO2aTxhKv7At",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1618
        },
        "outputId": "3a788980-5ea0-4ff1-97e9-b7cb59efefcf"
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "model_ted_wv = Word2Vec(sentences=sentences_ted, size=100, window=5, min_count=5, workers=4, sg=0)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-09-17 18:19:02,206 : INFO : 'pattern' package not found; tag filters are not available for English\n",
            "2018-09-17 18:19:02,214 : INFO : collecting all words and their counts\n",
            "2018-09-17 18:19:02,216 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-09-17 18:19:02,260 : INFO : PROGRESS: at sentence #10000, processed 172561 words, keeping 12186 word types\n",
            "2018-09-17 18:19:02,305 : INFO : PROGRESS: at sentence #20000, processed 344873 words, keeping 17274 word types\n",
            "2018-09-17 18:19:02,351 : INFO : PROGRESS: at sentence #30000, processed 516752 words, keeping 20770 word types\n",
            "2018-09-17 18:19:02,402 : INFO : PROGRESS: at sentence #40000, processed 704349 words, keeping 23855 word types\n",
            "2018-09-17 18:19:02,454 : INFO : PROGRESS: at sentence #50000, processed 889918 words, keeping 26831 word types\n",
            "2018-09-17 18:19:02,509 : INFO : PROGRESS: at sentence #60000, processed 1073225 words, keeping 28991 word types\n",
            "2018-09-17 18:19:02,559 : INFO : PROGRESS: at sentence #70000, processed 1249812 words, keeping 31170 word types\n",
            "2018-09-17 18:19:02,608 : INFO : PROGRESS: at sentence #80000, processed 1419638 words, keeping 32904 word types\n",
            "2018-09-17 18:19:02,657 : INFO : PROGRESS: at sentence #90000, processed 1597488 words, keeping 34632 word types\n",
            "2018-09-17 18:19:02,706 : INFO : PROGRESS: at sentence #100000, processed 1779455 words, keeping 36362 word types\n",
            "2018-09-17 18:19:02,754 : INFO : PROGRESS: at sentence #110000, processed 1942483 words, keeping 37761 word types\n",
            "2018-09-17 18:19:02,803 : INFO : PROGRESS: at sentence #120000, processed 2111710 words, keeping 39167 word types\n",
            "2018-09-17 18:19:02,849 : INFO : PROGRESS: at sentence #130000, processed 2273484 words, keeping 40538 word types\n",
            "2018-09-17 18:19:02,895 : INFO : PROGRESS: at sentence #140000, processed 2434079 words, keeping 41797 word types\n",
            "2018-09-17 18:19:02,944 : INFO : PROGRESS: at sentence #150000, processed 2603155 words, keeping 42952 word types\n",
            "2018-09-17 18:19:02,996 : INFO : PROGRESS: at sentence #160000, processed 2769643 words, keeping 44101 word types\n",
            "2018-09-17 18:19:03,044 : INFO : PROGRESS: at sentence #170000, processed 2931209 words, keeping 45256 word types\n",
            "2018-09-17 18:19:03,086 : INFO : PROGRESS: at sentence #180000, processed 3085920 words, keeping 46253 word types\n",
            "2018-09-17 18:19:03,132 : INFO : PROGRESS: at sentence #190000, processed 3230672 words, keeping 47227 word types\n",
            "2018-09-17 18:19:03,174 : INFO : PROGRESS: at sentence #200000, processed 3378005 words, keeping 48155 word types\n",
            "2018-09-17 18:19:03,225 : INFO : PROGRESS: at sentence #210000, processed 3551834 words, keeping 49399 word types\n",
            "2018-09-17 18:19:03,274 : INFO : PROGRESS: at sentence #220000, processed 3717331 words, keeping 50392 word types\n",
            "2018-09-17 18:19:03,317 : INFO : PROGRESS: at sentence #230000, processed 3869445 words, keeping 51188 word types\n",
            "2018-09-17 18:19:03,364 : INFO : PROGRESS: at sentence #240000, processed 4026045 words, keeping 52082 word types\n",
            "2018-09-17 18:19:03,411 : INFO : PROGRESS: at sentence #250000, processed 4188251 words, keeping 52902 word types\n",
            "2018-09-17 18:19:03,460 : INFO : PROGRESS: at sentence #260000, processed 4358330 words, keeping 53961 word types\n",
            "2018-09-17 18:19:03,488 : INFO : collected 54454 word types from a corpus of 4466832 raw words and 266694 sentences\n",
            "2018-09-17 18:19:03,490 : INFO : Loading a fresh vocabulary\n",
            "2018-09-17 18:19:03,567 : INFO : effective_min_count=5 retains 21444 unique words (39% of original 54454, drops 33010)\n",
            "2018-09-17 18:19:03,569 : INFO : effective_min_count=5 leaves 4408868 word corpus (98% of original 4466832, drops 57964)\n",
            "2018-09-17 18:19:03,652 : INFO : deleting the raw counts dictionary of 54454 items\n",
            "2018-09-17 18:19:03,655 : INFO : sample=0.001 downsamples 56 most-common words\n",
            "2018-09-17 18:19:03,657 : INFO : downsampling leaves estimated 3171553 word corpus (71.9% of prior 4408868)\n",
            "2018-09-17 18:19:03,763 : INFO : estimated required memory for 21444 words and 100 dimensions: 27877200 bytes\n",
            "2018-09-17 18:19:03,764 : INFO : resetting layer weights\n",
            "2018-09-17 18:19:04,029 : INFO : training model with 4 workers on 21444 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2018-09-17 18:19:05,042 : INFO : EPOCH 1 - PROGRESS: at 14.88% examples, 501019 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:06,056 : INFO : EPOCH 1 - PROGRESS: at 30.81% examples, 517744 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:07,065 : INFO : EPOCH 1 - PROGRESS: at 47.46% examples, 523458 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:08,066 : INFO : EPOCH 1 - PROGRESS: at 64.09% examples, 521626 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:09,066 : INFO : EPOCH 1 - PROGRESS: at 81.94% examples, 522856 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:10,049 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:19:10,057 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:19:10,062 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:19:10,080 : INFO : EPOCH 1 - PROGRESS: at 100.00% examples, 525099 words/s, in_qsize 0, out_qsize 1\n",
            "2018-09-17 18:19:10,081 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:19:10,083 : INFO : EPOCH - 1 : training on 4466832 raw words (3171136 effective words) took 6.0s, 524865 effective words/s\n",
            "2018-09-17 18:19:11,102 : INFO : EPOCH 2 - PROGRESS: at 15.71% examples, 525442 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:12,134 : INFO : EPOCH 2 - PROGRESS: at 31.24% examples, 518022 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:13,143 : INFO : EPOCH 2 - PROGRESS: at 47.24% examples, 516370 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:14,161 : INFO : EPOCH 2 - PROGRESS: at 64.31% examples, 519079 words/s, in_qsize 8, out_qsize 2\n",
            "2018-09-17 18:19:15,185 : INFO : EPOCH 2 - PROGRESS: at 82.42% examples, 518694 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:16,137 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:19:16,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:19:16,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:19:16,159 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:19:16,160 : INFO : EPOCH - 2 : training on 4466832 raw words (3171531 effective words) took 6.1s, 522607 effective words/s\n",
            "2018-09-17 18:19:17,189 : INFO : EPOCH 3 - PROGRESS: at 15.71% examples, 522540 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:18,192 : INFO : EPOCH 3 - PROGRESS: at 31.24% examples, 524045 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:19,195 : INFO : EPOCH 3 - PROGRESS: at 47.66% examples, 526140 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:19:20,213 : INFO : EPOCH 3 - PROGRESS: at 64.31% examples, 521499 words/s, in_qsize 7, out_qsize 1\n",
            "2018-09-17 18:19:21,213 : INFO : EPOCH 3 - PROGRESS: at 82.19% examples, 522694 words/s, in_qsize 8, out_qsize 1\n",
            "2018-09-17 18:19:22,186 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:19:22,191 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:19:22,200 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:19:22,220 : INFO : EPOCH 3 - PROGRESS: at 100.00% examples, 524392 words/s, in_qsize 0, out_qsize 1\n",
            "2018-09-17 18:19:22,222 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:19:22,223 : INFO : EPOCH - 3 : training on 4466832 raw words (3171170 effective words) took 6.1s, 524151 effective words/s\n",
            "2018-09-17 18:19:23,262 : INFO : EPOCH 4 - PROGRESS: at 15.71% examples, 528506 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:19:24,264 : INFO : EPOCH 4 - PROGRESS: at 31.67% examples, 534440 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:25,286 : INFO : EPOCH 4 - PROGRESS: at 47.72% examples, 525102 words/s, in_qsize 5, out_qsize 2\n",
            "2018-09-17 18:19:26,325 : INFO : EPOCH 4 - PROGRESS: at 65.20% examples, 525016 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:27,353 : INFO : EPOCH 4 - PROGRESS: at 83.57% examples, 525555 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:28,231 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:19:28,238 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:19:28,242 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:19:28,251 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:19:28,252 : INFO : EPOCH - 4 : training on 4466832 raw words (3172815 effective words) took 6.0s, 529305 effective words/s\n",
            "2018-09-17 18:19:29,274 : INFO : EPOCH 5 - PROGRESS: at 15.71% examples, 526396 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:30,314 : INFO : EPOCH 5 - PROGRESS: at 31.24% examples, 518991 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:31,304 : INFO : EPOCH 5 - PROGRESS: at 47.24% examples, 518689 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:32,311 : INFO : EPOCH 5 - PROGRESS: at 64.09% examples, 519055 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:19:33,312 : INFO : EPOCH 5 - PROGRESS: at 82.19% examples, 522233 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:34,292 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:19:34,303 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:19:34,319 : INFO : EPOCH 5 - PROGRESS: at 99.73% examples, 522825 words/s, in_qsize 1, out_qsize 1\n",
            "2018-09-17 18:19:34,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:19:34,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:19:34,325 : INFO : EPOCH - 5 : training on 4466832 raw words (3171941 effective words) took 6.1s, 523437 effective words/s\n",
            "2018-09-17 18:19:34,327 : INFO : training on a 22334160 raw words (15858593 effective words) took 30.3s, 523455 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CVYSduwUv7A8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "7cf3eebc-3c00-43cd-b14d-7ed9ff01c7ab"
      },
      "cell_type": "code",
      "source": [
        "model_ted_wv.wv.most_similar(\"man\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-09-17 18:19:35,260 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.8531621694564819),\n",
              " ('guy', 0.8057481050491333),\n",
              " ('soldier', 0.7574235796928406),\n",
              " ('lady', 0.7569026350975037),\n",
              " ('boy', 0.7550076246261597),\n",
              " ('girl', 0.7447366714477539),\n",
              " ('gentleman', 0.7282483577728271),\n",
              " ('poet', 0.7053318023681641),\n",
              " ('david', 0.698114812374115),\n",
              " ('kid', 0.669856607913971)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "waUgwuSEwjIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "1827d0bc-b3b3-43c5-d8a2-360980933d4b"
      },
      "cell_type": "code",
      "source": [
        "model_ted_wv.wv.most_similar(\"Hitman\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-91b56661b9b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ted_wv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hitman\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'Hitman' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KmI5JbbKv7A8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4355
        },
        "outputId": "9068478a-b446-4e7d-b39f-01e4dff63d8c"
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "model_ted_ft = FastText(sentences_ted, size=100, window=5, min_count=5, workers=4,sg=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-09-17 18:19:36,722 : INFO : collecting all words and their counts\n",
            "2018-09-17 18:19:36,725 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-09-17 18:19:36,769 : INFO : PROGRESS: at sentence #10000, processed 172561 words, keeping 12186 word types\n",
            "2018-09-17 18:19:36,810 : INFO : PROGRESS: at sentence #20000, processed 344873 words, keeping 17274 word types\n",
            "2018-09-17 18:19:36,849 : INFO : PROGRESS: at sentence #30000, processed 516752 words, keeping 20770 word types\n",
            "2018-09-17 18:19:36,895 : INFO : PROGRESS: at sentence #40000, processed 704349 words, keeping 23855 word types\n",
            "2018-09-17 18:19:36,938 : INFO : PROGRESS: at sentence #50000, processed 889918 words, keeping 26831 word types\n",
            "2018-09-17 18:19:36,983 : INFO : PROGRESS: at sentence #60000, processed 1073225 words, keeping 28991 word types\n",
            "2018-09-17 18:19:37,024 : INFO : PROGRESS: at sentence #70000, processed 1249812 words, keeping 31170 word types\n",
            "2018-09-17 18:19:37,065 : INFO : PROGRESS: at sentence #80000, processed 1419638 words, keeping 32904 word types\n",
            "2018-09-17 18:19:37,108 : INFO : PROGRESS: at sentence #90000, processed 1597488 words, keeping 34632 word types\n",
            "2018-09-17 18:19:37,150 : INFO : PROGRESS: at sentence #100000, processed 1779455 words, keeping 36362 word types\n",
            "2018-09-17 18:19:37,191 : INFO : PROGRESS: at sentence #110000, processed 1942483 words, keeping 37761 word types\n",
            "2018-09-17 18:19:37,234 : INFO : PROGRESS: at sentence #120000, processed 2111710 words, keeping 39167 word types\n",
            "2018-09-17 18:19:37,276 : INFO : PROGRESS: at sentence #130000, processed 2273484 words, keeping 40538 word types\n",
            "2018-09-17 18:19:37,319 : INFO : PROGRESS: at sentence #140000, processed 2434079 words, keeping 41797 word types\n",
            "2018-09-17 18:19:37,362 : INFO : PROGRESS: at sentence #150000, processed 2603155 words, keeping 42952 word types\n",
            "2018-09-17 18:19:37,407 : INFO : PROGRESS: at sentence #160000, processed 2769643 words, keeping 44101 word types\n",
            "2018-09-17 18:19:37,448 : INFO : PROGRESS: at sentence #170000, processed 2931209 words, keeping 45256 word types\n",
            "2018-09-17 18:19:37,491 : INFO : PROGRESS: at sentence #180000, processed 3085920 words, keeping 46253 word types\n",
            "2018-09-17 18:19:37,527 : INFO : PROGRESS: at sentence #190000, processed 3230672 words, keeping 47227 word types\n",
            "2018-09-17 18:19:37,568 : INFO : PROGRESS: at sentence #200000, processed 3378005 words, keeping 48155 word types\n",
            "2018-09-17 18:19:37,615 : INFO : PROGRESS: at sentence #210000, processed 3551834 words, keeping 49399 word types\n",
            "2018-09-17 18:19:37,654 : INFO : PROGRESS: at sentence #220000, processed 3717331 words, keeping 50392 word types\n",
            "2018-09-17 18:19:37,694 : INFO : PROGRESS: at sentence #230000, processed 3869445 words, keeping 51188 word types\n",
            "2018-09-17 18:19:37,739 : INFO : PROGRESS: at sentence #240000, processed 4026045 words, keeping 52082 word types\n",
            "2018-09-17 18:19:37,780 : INFO : PROGRESS: at sentence #250000, processed 4188251 words, keeping 52902 word types\n",
            "2018-09-17 18:19:37,832 : INFO : PROGRESS: at sentence #260000, processed 4358330 words, keeping 53961 word types\n",
            "2018-09-17 18:19:37,859 : INFO : collected 54454 word types from a corpus of 4466832 raw words and 266694 sentences\n",
            "2018-09-17 18:19:37,861 : INFO : Loading a fresh vocabulary\n",
            "2018-09-17 18:19:37,935 : INFO : effective_min_count=5 retains 21444 unique words (39% of original 54454, drops 33010)\n",
            "2018-09-17 18:19:37,936 : INFO : effective_min_count=5 leaves 4408868 word corpus (98% of original 4466832, drops 57964)\n",
            "2018-09-17 18:19:38,019 : INFO : deleting the raw counts dictionary of 54454 items\n",
            "2018-09-17 18:19:38,022 : INFO : sample=0.001 downsamples 56 most-common words\n",
            "2018-09-17 18:19:38,024 : INFO : downsampling leaves estimated 3171553 word corpus (71.9% of prior 4408868)\n",
            "2018-09-17 18:19:40,127 : INFO : estimated required memory for 21444 words, 113592 buckets and 100 dimensions: 78363416 bytes\n",
            "2018-09-17 18:19:40,138 : INFO : resetting layer weights\n",
            "2018-09-17 18:19:41,627 : INFO : Total number of ngrams is 113592\n",
            "2018-09-17 18:19:42,616 : INFO : training model with 4 workers on 21444 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
            "2018-09-17 18:19:43,649 : INFO : EPOCH 1 - PROGRESS: at 1.78% examples, 56780 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:44,675 : INFO : EPOCH 1 - PROGRESS: at 4.36% examples, 70217 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:45,842 : INFO : EPOCH 1 - PROGRESS: at 6.97% examples, 71434 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:46,986 : INFO : EPOCH 1 - PROGRESS: at 9.81% examples, 74087 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:48,115 : INFO : EPOCH 1 - PROGRESS: at 12.34% examples, 74605 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:49,123 : INFO : EPOCH 1 - PROGRESS: at 14.32% examples, 74058 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:50,266 : INFO : EPOCH 1 - PROGRESS: at 16.49% examples, 73277 words/s, in_qsize 7, out_qsize 2\n",
            "2018-09-17 18:19:51,391 : INFO : EPOCH 1 - PROGRESS: at 19.18% examples, 75079 words/s, in_qsize 7, out_qsize 1\n",
            "2018-09-17 18:19:52,337 : INFO : EPOCH 1 - PROGRESS: at 21.41% examples, 75232 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:19:53,357 : INFO : EPOCH 1 - PROGRESS: at 23.45% examples, 74771 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:54,414 : INFO : EPOCH 1 - PROGRESS: at 25.53% examples, 74104 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:55,616 : INFO : EPOCH 1 - PROGRESS: at 28.40% examples, 74966 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:56,518 : INFO : EPOCH 1 - PROGRESS: at 30.61% examples, 74640 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:19:57,545 : INFO : EPOCH 1 - PROGRESS: at 33.13% examples, 75241 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:58,637 : INFO : EPOCH 1 - PROGRESS: at 35.53% examples, 75414 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:19:59,650 : INFO : EPOCH 1 - PROGRESS: at 37.88% examples, 75516 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:00,681 : INFO : EPOCH 1 - PROGRESS: at 40.41% examples, 75554 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:01,708 : INFO : EPOCH 1 - PROGRESS: at 42.83% examples, 75575 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:02,871 : INFO : EPOCH 1 - PROGRESS: at 45.86% examples, 75768 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:03,966 : INFO : EPOCH 1 - PROGRESS: at 48.59% examples, 75862 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:05,086 : INFO : EPOCH 1 - PROGRESS: at 50.93% examples, 75212 words/s, in_qsize 8, out_qsize 2\n",
            "2018-09-17 18:20:06,163 : INFO : EPOCH 1 - PROGRESS: at 54.11% examples, 75997 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:07,193 : INFO : EPOCH 1 - PROGRESS: at 56.31% examples, 75691 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:08,204 : INFO : EPOCH 1 - PROGRESS: at 58.76% examples, 75753 words/s, in_qsize 7, out_qsize 2\n",
            "2018-09-17 18:20:09,204 : INFO : EPOCH 1 - PROGRESS: at 61.53% examples, 76094 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:10,230 : INFO : EPOCH 1 - PROGRESS: at 64.08% examples, 76099 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:11,412 : INFO : EPOCH 1 - PROGRESS: at 67.24% examples, 76166 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:12,476 : INFO : EPOCH 1 - PROGRESS: at 70.55% examples, 76538 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:13,534 : INFO : EPOCH 1 - PROGRESS: at 73.75% examples, 76649 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:14,577 : INFO : EPOCH 1 - PROGRESS: at 76.12% examples, 76346 words/s, in_qsize 5, out_qsize 2\n",
            "2018-09-17 18:20:15,617 : INFO : EPOCH 1 - PROGRESS: at 78.81% examples, 76701 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:16,761 : INFO : EPOCH 1 - PROGRESS: at 81.50% examples, 76596 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:17,849 : INFO : EPOCH 1 - PROGRESS: at 84.64% examples, 76838 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:18,950 : INFO : EPOCH 1 - PROGRESS: at 87.61% examples, 76825 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:20,088 : INFO : EPOCH 1 - PROGRESS: at 90.41% examples, 76979 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:21,101 : INFO : EPOCH 1 - PROGRESS: at 92.88% examples, 76732 words/s, in_qsize 5, out_qsize 2\n",
            "2018-09-17 18:20:22,138 : INFO : EPOCH 1 - PROGRESS: at 95.90% examples, 77025 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:23,264 : INFO : EPOCH 1 - PROGRESS: at 98.24% examples, 76803 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:23,540 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:20:23,632 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:20:23,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:20:23,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:20:23,665 : INFO : EPOCH - 1 : training on 4466832 raw words (3172016 effective words) took 41.0s, 77301 effective words/s\n",
            "2018-09-17 18:20:24,804 : INFO : EPOCH 2 - PROGRESS: at 2.20% examples, 64311 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:25,832 : INFO : EPOCH 2 - PROGRESS: at 4.78% examples, 73298 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:26,938 : INFO : EPOCH 2 - PROGRESS: at 7.19% examples, 72637 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:28,034 : INFO : EPOCH 2 - PROGRESS: at 9.81% examples, 74101 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:29,072 : INFO : EPOCH 2 - PROGRESS: at 11.92% examples, 73183 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:30,116 : INFO : EPOCH 2 - PROGRESS: at 14.26% examples, 74686 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:31,186 : INFO : EPOCH 2 - PROGRESS: at 16.49% examples, 74510 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:32,210 : INFO : EPOCH 2 - PROGRESS: at 18.73% examples, 74736 words/s, in_qsize 8, out_qsize 1\n",
            "2018-09-17 18:20:33,215 : INFO : EPOCH 2 - PROGRESS: at 20.76% examples, 74341 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:34,376 : INFO : EPOCH 2 - PROGRESS: at 23.00% examples, 73618 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:20:35,526 : INFO : EPOCH 2 - PROGRESS: at 25.55% examples, 73674 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:36,617 : INFO : EPOCH 2 - PROGRESS: at 28.20% examples, 74083 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:37,655 : INFO : EPOCH 2 - PROGRESS: at 30.81% examples, 74680 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:38,748 : INFO : EPOCH 2 - PROGRESS: at 33.13% examples, 74467 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:39,884 : INFO : EPOCH 2 - PROGRESS: at 35.53% examples, 74485 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:41,002 : INFO : EPOCH 2 - PROGRESS: at 38.27% examples, 74996 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:42,288 : INFO : EPOCH 2 - PROGRESS: at 41.35% examples, 74803 words/s, in_qsize 7, out_qsize 2\n",
            "2018-09-17 18:20:43,430 : INFO : EPOCH 2 - PROGRESS: at 44.40% examples, 75473 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:44,563 : INFO : EPOCH 2 - PROGRESS: at 47.01% examples, 75106 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:45,565 : INFO : EPOCH 2 - PROGRESS: at 49.75% examples, 75544 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:46,641 : INFO : EPOCH 2 - PROGRESS: at 52.61% examples, 75701 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:47,662 : INFO : EPOCH 2 - PROGRESS: at 54.98% examples, 75726 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:20:48,743 : INFO : EPOCH 2 - PROGRESS: at 57.65% examples, 75848 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:49,760 : INFO : EPOCH 2 - PROGRESS: at 60.14% examples, 75875 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:50,781 : INFO : EPOCH 2 - PROGRESS: at 62.87% examples, 76159 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:51,842 : INFO : EPOCH 2 - PROGRESS: at 65.24% examples, 75826 words/s, in_qsize 7, out_qsize 1\n",
            "2018-09-17 18:20:53,001 : INFO : EPOCH 2 - PROGRESS: at 68.78% examples, 76184 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:54,069 : INFO : EPOCH 2 - PROGRESS: at 71.57% examples, 76069 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:55,249 : INFO : EPOCH 2 - PROGRESS: at 75.02% examples, 76122 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:56,368 : INFO : EPOCH 2 - PROGRESS: at 77.99% examples, 76521 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:57,374 : INFO : EPOCH 2 - PROGRESS: at 80.41% examples, 76513 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:20:58,569 : INFO : EPOCH 2 - PROGRESS: at 83.11% examples, 76315 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:20:59,648 : INFO : EPOCH 2 - PROGRESS: at 86.38% examples, 76577 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:00,696 : INFO : EPOCH 2 - PROGRESS: at 89.22% examples, 76673 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:01,738 : INFO : EPOCH 2 - PROGRESS: at 91.71% examples, 76610 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:02,784 : INFO : EPOCH 2 - PROGRESS: at 94.63% examples, 76715 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:04,001 : INFO : EPOCH 2 - PROGRESS: at 97.15% examples, 76495 words/s, in_qsize 7, out_qsize 1\n",
            "2018-09-17 18:21:04,739 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:21:04,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:21:04,841 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:21:04,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:21:04,849 : INFO : EPOCH - 2 : training on 4466832 raw words (3171082 effective words) took 41.2s, 77029 effective words/s\n",
            "2018-09-17 18:21:05,885 : INFO : EPOCH 3 - PROGRESS: at 1.99% examples, 63220 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:06,905 : INFO : EPOCH 3 - PROGRESS: at 4.36% examples, 70135 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:08,050 : INFO : EPOCH 3 - PROGRESS: at 6.97% examples, 71929 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:09,055 : INFO : EPOCH 3 - PROGRESS: at 9.36% examples, 73540 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:10,193 : INFO : EPOCH 3 - PROGRESS: at 11.92% examples, 73985 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:11,421 : INFO : EPOCH 3 - PROGRESS: at 14.32% examples, 73248 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:12,478 : INFO : EPOCH 3 - PROGRESS: at 16.68% examples, 74334 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:13,584 : INFO : EPOCH 3 - PROGRESS: at 19.18% examples, 74731 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:14,628 : INFO : EPOCH 3 - PROGRESS: at 21.20% examples, 74023 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:15,801 : INFO : EPOCH 3 - PROGRESS: at 23.64% examples, 73944 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:16,854 : INFO : EPOCH 3 - PROGRESS: at 26.19% examples, 74549 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:17,859 : INFO : EPOCH 3 - PROGRESS: at 28.62% examples, 74827 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:18,965 : INFO : EPOCH 3 - PROGRESS: at 31.24% examples, 74996 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:20,000 : INFO : EPOCH 3 - PROGRESS: at 33.54% examples, 75050 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:21,089 : INFO : EPOCH 3 - PROGRESS: at 35.75% examples, 74845 words/s, in_qsize 7, out_qsize 1\n",
            "2018-09-17 18:21:22,195 : INFO : EPOCH 3 - PROGRESS: at 38.52% examples, 75388 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:23,313 : INFO : EPOCH 3 - PROGRESS: at 41.33% examples, 75448 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:24,320 : INFO : EPOCH 3 - PROGRESS: at 43.48% examples, 75169 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:25,376 : INFO : EPOCH 3 - PROGRESS: at 46.33% examples, 75436 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:26,400 : INFO : EPOCH 3 - PROGRESS: at 49.05% examples, 75805 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:27,492 : INFO : EPOCH 3 - PROGRESS: at 51.91% examples, 75890 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:28,502 : INFO : EPOCH 3 - PROGRESS: at 54.35% examples, 75935 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:29,598 : INFO : EPOCH 3 - PROGRESS: at 57.00% examples, 76017 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:30,622 : INFO : EPOCH 3 - PROGRESS: at 59.46% examples, 76015 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:31,839 : INFO : EPOCH 3 - PROGRESS: at 62.21% examples, 75737 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:32,954 : INFO : EPOCH 3 - PROGRESS: at 65.42% examples, 76266 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:34,165 : INFO : EPOCH 3 - PROGRESS: at 68.56% examples, 76003 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:35,268 : INFO : EPOCH 3 - PROGRESS: at 71.64% examples, 76050 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:36,351 : INFO : EPOCH 3 - PROGRESS: at 74.95% examples, 76336 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:37,456 : INFO : EPOCH 3 - PROGRESS: at 77.83% examples, 76555 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:21:38,651 : INFO : EPOCH 3 - PROGRESS: at 80.44% examples, 76317 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:39,724 : INFO : EPOCH 3 - PROGRESS: at 83.46% examples, 76604 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:40,841 : INFO : EPOCH 3 - PROGRESS: at 86.14% examples, 76380 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:41,953 : INFO : EPOCH 3 - PROGRESS: at 89.47% examples, 76729 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:43,043 : INFO : EPOCH 3 - PROGRESS: at 92.22% examples, 76761 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:44,177 : INFO : EPOCH 3 - PROGRESS: at 95.05% examples, 76687 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:45,205 : INFO : EPOCH 3 - PROGRESS: at 97.15% examples, 76477 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:45,926 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:21:45,994 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:21:46,013 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:21:46,045 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:21:46,047 : INFO : EPOCH - 3 : training on 4466832 raw words (3172326 effective words) took 41.2s, 77020 effective words/s\n",
            "2018-09-17 18:21:47,297 : INFO : EPOCH 4 - PROGRESS: at 2.40% examples, 69733 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:48,267 : INFO : EPOCH 4 - PROGRESS: at 4.78% examples, 71491 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:49,320 : INFO : EPOCH 4 - PROGRESS: at 7.19% examples, 72563 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:50,404 : INFO : EPOCH 4 - PROGRESS: at 9.38% examples, 70941 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:21:51,609 : INFO : EPOCH 4 - PROGRESS: at 12.14% examples, 72390 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:52,657 : INFO : EPOCH 4 - PROGRESS: at 14.49% examples, 73967 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:53,742 : INFO : EPOCH 4 - PROGRESS: at 16.88% examples, 74661 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:21:54,893 : INFO : EPOCH 4 - PROGRESS: at 19.36% examples, 74592 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:55,972 : INFO : EPOCH 4 - PROGRESS: at 21.41% examples, 73668 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:57,177 : INFO : EPOCH 4 - PROGRESS: at 23.62% examples, 72775 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:21:58,305 : INFO : EPOCH 4 - PROGRESS: at 25.94% examples, 72462 words/s, in_qsize 5, out_qsize 2\n",
            "2018-09-17 18:21:59,388 : INFO : EPOCH 4 - PROGRESS: at 28.62% examples, 73001 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:00,482 : INFO : EPOCH 4 - PROGRESS: at 31.04% examples, 72892 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:01,569 : INFO : EPOCH 4 - PROGRESS: at 32.94% examples, 71914 words/s, in_qsize 8, out_qsize 2\n",
            "2018-09-17 18:22:02,641 : INFO : EPOCH 4 - PROGRESS: at 35.10% examples, 71970 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:03,765 : INFO : EPOCH 4 - PROGRESS: at 37.68% examples, 72214 words/s, in_qsize 7, out_qsize 1\n",
            "2018-09-17 18:22:04,791 : INFO : EPOCH 4 - PROGRESS: at 40.14% examples, 72449 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:22:05,829 : INFO : EPOCH 4 - PROGRESS: at 42.61% examples, 72596 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:06,919 : INFO : EPOCH 4 - PROGRESS: at 44.91% examples, 72180 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:08,009 : INFO : EPOCH 4 - PROGRESS: at 47.66% examples, 72468 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:09,071 : INFO : EPOCH 4 - PROGRESS: at 50.17% examples, 72500 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:10,076 : INFO : EPOCH 4 - PROGRESS: at 52.82% examples, 72709 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:11,119 : INFO : EPOCH 4 - PROGRESS: at 54.98% examples, 72498 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:12,214 : INFO : EPOCH 4 - PROGRESS: at 57.71% examples, 72715 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:13,249 : INFO : EPOCH 4 - PROGRESS: at 59.92% examples, 72540 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:14,355 : INFO : EPOCH 4 - PROGRESS: at 62.67% examples, 72710 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:15,362 : INFO : EPOCH 4 - PROGRESS: at 65.42% examples, 73115 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:16,430 : INFO : EPOCH 4 - PROGRESS: at 68.52% examples, 73323 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:17,498 : INFO : EPOCH 4 - PROGRESS: at 71.64% examples, 73534 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:18,552 : INFO : EPOCH 4 - PROGRESS: at 74.75% examples, 73752 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:19,617 : INFO : EPOCH 4 - PROGRESS: at 77.20% examples, 73723 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:20,647 : INFO : EPOCH 4 - PROGRESS: at 79.77% examples, 73949 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:21,661 : INFO : EPOCH 4 - PROGRESS: at 82.42% examples, 74219 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:22,668 : INFO : EPOCH 4 - PROGRESS: at 85.14% examples, 74302 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:23,741 : INFO : EPOCH 4 - PROGRESS: at 88.01% examples, 74414 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:24,754 : INFO : EPOCH 4 - PROGRESS: at 90.40% examples, 74273 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:25,757 : INFO : EPOCH 4 - PROGRESS: at 93.17% examples, 74524 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:26,850 : INFO : EPOCH 4 - PROGRESS: at 95.75% examples, 74416 words/s, in_qsize 5, out_qsize 2\n",
            "2018-09-17 18:22:27,883 : INFO : EPOCH 4 - PROGRESS: at 98.44% examples, 74768 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:28,247 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:22:28,274 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:22:28,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:22:28,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:22:28,325 : INFO : EPOCH - 4 : training on 4466832 raw words (3171182 effective words) took 42.3s, 75033 effective words/s\n",
            "2018-09-17 18:22:29,413 : INFO : EPOCH 5 - PROGRESS: at 2.20% examples, 67129 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:30,418 : INFO : EPOCH 5 - PROGRESS: at 4.34% examples, 68992 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:31,445 : INFO : EPOCH 5 - PROGRESS: at 6.75% examples, 71486 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:32,485 : INFO : EPOCH 5 - PROGRESS: at 8.88% examples, 70871 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:33,563 : INFO : EPOCH 5 - PROGRESS: at 11.70% examples, 74101 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:34,610 : INFO : EPOCH 5 - PROGRESS: at 13.74% examples, 73155 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:35,635 : INFO : EPOCH 5 - PROGRESS: at 16.10% examples, 74686 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:36,722 : INFO : EPOCH 5 - PROGRESS: at 18.30% examples, 74325 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:37,876 : INFO : EPOCH 5 - PROGRESS: at 20.61% examples, 73546 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:38,919 : INFO : EPOCH 5 - PROGRESS: at 22.81% examples, 73721 words/s, in_qsize 5, out_qsize 2\n",
            "2018-09-17 18:22:39,949 : INFO : EPOCH 5 - PROGRESS: at 25.34% examples, 74544 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:40,960 : INFO : EPOCH 5 - PROGRESS: at 27.75% examples, 74771 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:42,240 : INFO : EPOCH 5 - PROGRESS: at 30.39% examples, 74021 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:43,357 : INFO : EPOCH 5 - PROGRESS: at 32.94% examples, 74181 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:44,397 : INFO : EPOCH 5 - PROGRESS: at 35.10% examples, 74236 words/s, in_qsize 5, out_qsize 2\n",
            "2018-09-17 18:22:45,409 : INFO : EPOCH 5 - PROGRESS: at 37.46% examples, 74388 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:46,600 : INFO : EPOCH 5 - PROGRESS: at 40.37% examples, 74606 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:47,746 : INFO : EPOCH 5 - PROGRESS: at 43.06% examples, 74596 words/s, in_qsize 7, out_qsize 1\n",
            "2018-09-17 18:22:48,803 : INFO : EPOCH 5 - PROGRESS: at 46.12% examples, 75220 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:49,820 : INFO : EPOCH 5 - PROGRESS: at 48.59% examples, 75289 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:50,893 : INFO : EPOCH 5 - PROGRESS: at 51.39% examples, 75475 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:51,952 : INFO : EPOCH 5 - PROGRESS: at 54.14% examples, 75682 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:52,988 : INFO : EPOCH 5 - PROGRESS: at 56.52% examples, 75659 words/s, in_qsize 8, out_qsize 0\n",
            "2018-09-17 18:22:54,076 : INFO : EPOCH 5 - PROGRESS: at 59.25% examples, 75765 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:55,157 : INFO : EPOCH 5 - PROGRESS: at 61.77% examples, 75627 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:56,185 : INFO : EPOCH 5 - PROGRESS: at 64.56% examples, 75892 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:57,327 : INFO : EPOCH 5 - PROGRESS: at 67.49% examples, 75821 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:22:58,333 : INFO : EPOCH 5 - PROGRESS: at 70.54% examples, 76099 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:22:59,390 : INFO : EPOCH 5 - PROGRESS: at 73.51% examples, 76000 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:23:00,421 : INFO : EPOCH 5 - PROGRESS: at 75.89% examples, 75762 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:23:01,453 : INFO : EPOCH 5 - PROGRESS: at 78.40% examples, 75944 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:23:02,500 : INFO : EPOCH 5 - PROGRESS: at 81.09% examples, 76068 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:23:03,635 : INFO : EPOCH 5 - PROGRESS: at 83.92% examples, 76025 words/s, in_qsize 7, out_qsize 1\n",
            "2018-09-17 18:23:04,714 : INFO : EPOCH 5 - PROGRESS: at 87.14% examples, 76287 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:23:05,798 : INFO : EPOCH 5 - PROGRESS: at 89.95% examples, 76321 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:23:06,908 : INFO : EPOCH 5 - PROGRESS: at 92.71% examples, 76317 words/s, in_qsize 6, out_qsize 1\n",
            "2018-09-17 18:23:07,909 : INFO : EPOCH 5 - PROGRESS: at 95.05% examples, 76145 words/s, in_qsize 7, out_qsize 2\n",
            "2018-09-17 18:23:08,957 : INFO : EPOCH 5 - PROGRESS: at 97.80% examples, 76441 words/s, in_qsize 7, out_qsize 0\n",
            "2018-09-17 18:23:09,538 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-09-17 18:23:09,628 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-09-17 18:23:09,649 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-09-17 18:23:09,696 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-09-17 18:23:09,698 : INFO : EPOCH - 5 : training on 4466832 raw words (3170450 effective words) took 41.4s, 76655 effective words/s\n",
            "2018-09-17 18:23:09,699 : INFO : training on a 22334160 raw words (15857056 effective words) took 207.1s, 76574 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rm1ODPBfwnqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "41f64bc1-5ff6-4f73-cfe7-c350a958b3c7"
      },
      "cell_type": "code",
      "source": [
        "model_ted_ft.wv.most_similar(\"man\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batman', 0.8135496377944946),\n",
              " ('woman', 0.7971199750900269),\n",
              " ('ekman', 0.7905158996582031),\n",
              " ('hoffman', 0.7802772521972656),\n",
              " ('shaman', 0.7646391987800598),\n",
              " ('foreman', 0.7645190954208374),\n",
              " ('stuntman', 0.7640399932861328),\n",
              " ('salman', 0.7622843384742737),\n",
              " ('wurman', 0.757695198059082),\n",
              " ('chapman', 0.7491511702537537)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Cp51v5mVv7BL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "a7037e2e-0280-44a7-f74f-e3375ed33055"
      },
      "cell_type": "code",
      "source": [
        "model_ted_ft.wv.most_similar(\"Hitman\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-09-17 18:25:09,505 : INFO : precomputing L2-norms of word weight vectors\n",
            "2018-09-17 18:25:09,545 : INFO : precomputing L2-norms of ngram weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('stuntman', 0.8959266543388367),\n",
              " ('craftsman', 0.8656678199768066),\n",
              " ('seligman', 0.8425419926643372),\n",
              " ('batman', 0.8360868096351624),\n",
              " ('pseudonym', 0.8333516120910645),\n",
              " ('gottman', 0.8259511590003967),\n",
              " ('gymnosophist', 0.8253354430198669),\n",
              " ('wurman', 0.822790265083313),\n",
              " ('pseudo', 0.8210907578468323),\n",
              " ('chandelier', 0.8204042911529541)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "p6B7WXrav7B2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}